{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 13:39:51.550902: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-21 13:39:51.608679: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-21 13:39:52.696447: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "No ROCm runtime is found, using ROCM_HOME='/opt/rocm-6.1.2'\n"
     ]
    }
   ],
   "source": [
    "import os  # os 모듈 운영체제와 상호 작용할 수 있는 기능을 제공\n",
    "import torch # PyTorch 라이브러리로, 주로 딥러닝과 머신러닝 모델을 구축, 학습, 테스트하는 데 사용\n",
    "from datasets import load_dataset  # 데이터셋을 쉽게 불러오고 처리할 수 있는 기능을 제공\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM, # 인과적 언어 추론(예: GPT)을 위한 모델을 자동으로 불러오는 클래스\n",
    "    AutoTokenizer, # 입력 문장을 토큰 단위로 자동으로 잘라주는 역할 \n",
    "    BitsAndBytesConfig, # 모델 구성\n",
    "    HfArgumentParser,  # 파라미터 파싱\n",
    "    TrainingArguments,  # 훈련 설정\n",
    "    pipeline,  # 파이프라인 설정\n",
    "    logging,  #로깅을 위한 클래스\n",
    ")\n",
    "\n",
    "# 모델 튜닝을 위한 라이브러리\n",
    "from peft import LoraConfig, PeftModel  \n",
    "from trl import SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Current cuda device: 0\n",
      "Count of using GPUs: 3\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0,1,3\"  # Set the GPUs 2 and 3 to use\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Device:', device)\n",
    "print('Current cuda device:', torch.cuda.current_device())\n",
    "print('Count of using GPUs:', torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert llama weight to llamion weight\n",
    "#model_dir = \"../llama/llama-2-7b-chat-convert-weight\"\n",
    "model_dir = \"vaiv/Gem2-Llamion-14B-Base\"\n",
    "# REFT model\n",
    "new_model = \"llamion_peft\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dxlab/anaconda3/envs/obqa/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f118f61720f4d75a75a830eac15b805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    device_map='auto'\n",
    ")\n",
    "base_model.config.use_cache = False\n",
    "base_model.config.pretraining_tp = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dxlab/anaconda3/envs/obqa/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(model_dir, trust_remote_code=True)\n",
    "base_tokenizer.pad_token = base_tokenizer.eos_token\n",
    "base_tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "for param in base_model.parameters():\n",
    "  param.requires_grad = False  # freeze the model - train adapters later\n",
    "  if param.ndim == 1:\n",
    "    # cast the small parameters (e.g. layernorm) to fp32 for stability\n",
    "    param.data = param.data.to(torch.float32)\n",
    "\n",
    "base_model.gradient_checkpointing_enable()  # reduce number of stored activations\n",
    "base_model.enable_input_require_grads()\n",
    "\n",
    "class CastOutputToFloat(nn.Sequential):\n",
    "  def forward(self, x): return super().forward(x).to(torch.float32)\n",
    "base_model.lm_head = CastOutputToFloat(base_model.lm_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for param in base_model.parameters():\n",
    "#     print(param.requires_grad, sep=\"   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.arrow_dataset.Dataset'>\n",
      "(50, 4)\n",
      "Dataset({\n",
      "    features: ['question', 'context', 'chosen', 'rejected'],\n",
      "    num_rows: 50\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Data set\n",
    "# https://huggingface.co/datasets/mlabonne/guanaco-llama2-1k\n",
    "data_name = \"vaiv/ko-rag-preference\"\n",
    "training_data = load_dataset(data_name, split=\"validation\")\n",
    "\n",
    "print(type(training_data))\n",
    "# check the data\n",
    "print(training_data.shape)\n",
    "# #11 is a QA sample in English\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/dxlab/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/home/dxlab/anaconda3/envs/obqa/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "class PolyEncoder(torch.nn.Module):\n",
    "    def __init__(self, bert_model_name='klue/bert-base', poly_m=16):\n",
    "        super(PolyEncoder, self).__init__()\n",
    "        self.poly_m = poly_m\n",
    "        self.bert_model = BertModel.from_pretrained(bert_model_name)\n",
    "        self.poly_code_embeddings = torch.nn.Embedding(poly_m, self.bert_model.config.hidden_size)\n",
    "        \n",
    "    def forward(self, context_input_ids, context_attention_mask, question_input_ids, question_attention_mask):\n",
    "        # Encode the question\n",
    "        question_outputs = self.bert_model(input_ids=question_input_ids, attention_mask=question_attention_mask)\n",
    "        question_cls_embeddings = question_outputs.last_hidden_state[:, 0, :]  # CLS token\n",
    "\n",
    "        # Encode the context\n",
    "        context_outputs = self.bert_model(input_ids=context_input_ids, attention_mask=context_attention_mask)\n",
    "        context_hidden_states = context_outputs.last_hidden_state\n",
    "\n",
    "        # Poly codes\n",
    "        poly_codes = self.poly_code_embeddings.weight.unsqueeze(0).expand(context_hidden_states.size(0), -1, -1)\n",
    "\n",
    "        # Context and poly code interactions\n",
    "        attention_weights = F.softmax(torch.einsum('bmd,bnd->bmn', context_hidden_states, poly_codes), dim=-1)\n",
    "        poly_context_embeddings = torch.einsum('bmn,bmd->bnd', attention_weights, context_hidden_states)\n",
    "\n",
    "        # Question and poly context interactions\n",
    "        scores = torch.einsum('bnd,bmd->bnm', poly_context_embeddings, question_cls_embeddings.unsqueeze(1).expand(-1, self.poly_m, -1))\n",
    "\n",
    "        # Aggregate scores over poly_m dimension\n",
    "        scores = scores.max(dim=1).values\n",
    "\n",
    "        return scores\n",
    "\n",
    "def get_top_n_relevant_sentences(context, question, tokenizer, model, top_n):\n",
    "    context_sentences = sent_tokenize(context)  # NLTK를 사용하여 문장 분할\n",
    "    print(f\"Context sentences: {context_sentences}\")  # 문장 분할 결과 출력\n",
    "\n",
    "    context_inputs = tokenizer(context_sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "    question_inputs = tokenizer(question, return_tensors='pt')\n",
    "\n",
    "    # 입력 텐서의 길이 확인\n",
    "    print(f\"Context input IDs shape: {context_inputs['input_ids'].shape}\")\n",
    "    print(f\"Question input IDs shape: {question_inputs['input_ids'].shape}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scores = model(context_inputs['input_ids'], context_inputs['attention_mask'], \n",
    "                       question_inputs['input_ids'].expand(len(context_sentences), -1),\n",
    "                       question_inputs['attention_mask'].expand(len(context_sentences), -1))\n",
    "\n",
    "    # 디버깅용 출력\n",
    "    print(f\"Number of context sentences: {len(context_sentences)}\")\n",
    "    print(f\"Scores shape: {scores.shape}\")\n",
    "    score_rows, score_cols = scores.shape\n",
    "\n",
    "    print(f\"Scores: {scores}\")\n",
    "\n",
    "    scores_index = scores[:, 0].tolist()\n",
    "    print(scores_index)\n",
    "    indexed_dict = {idx: value for idx, value in enumerate(scores_index)}\n",
    "    sorted_dict = dict(sorted(indexed_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    sorted_data = sorted(sorted_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "    print(sorted_data)\n",
    "    top_n_keys = list(sorted_dict.keys())[:top_n]\n",
    "    unique_values = set()\n",
    "    top_keys = []\n",
    "\n",
    "    for key, value in sorted_data:\n",
    "        if value not in unique_values:\n",
    "            unique_values.add(value)\n",
    "            top_keys.append(key)\n",
    "        if len(top_keys) == top_n:\n",
    "            break\n",
    "\n",
    "    print(f\"Top {top_n} sentence indices: {top_keys}\")\n",
    "    top_n_sentences = [context_sentences[idx] for idx in top_keys]\n",
    "    return top_n_sentences\n",
    "\n",
    "# 모델 및 토크나이저 로드를 전역 변수로 설정\n",
    "tokenizer = BertTokenizer.from_pretrained('klue/bert-base')\n",
    "model = PolyEncoder(bert_model_name='klue/bert-base')\n",
    "\n",
    "# 예제 실행 함수\n",
    "def run_example(context, question):\n",
    "\n",
    "    top_n_sentences = get_top_n_relevant_sentences(context, question, tokenizer, model, top_n=5)\n",
    "    sentences = \"\"\n",
    "    for sentence in top_n_sentences:\n",
    "        sentences+=sentence\n",
    "    print(sentences)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "강한 자외선과 더운 날씨에 외출을 가급적 삼가를 해야 하며 몸으로 빠져나가는 수분을 이온음료, 물 등을 수시로 섭취하여 보충해줘야 합니다.또한, 규칙적으로 물을 마시고 몸에 수분이 부족하지 않도록 주의하는 것도 좋습니다.일사병은 대체적으로 염분과 수분의 부족으로 나타나는 경우가 많으므로 규칙적인 수분 섭취를 통해 예방할 수 있습니다.따라서 부득이하게 야외에 나갈 때는 챙이 넓은 모자를 쓰고 헐렁한 옷을 입는 것이 좋습니다.일시적으로 일사병의 증상이 나타나는 경우 서늘한 곳에서 휴식을 취하고 수분을 섭취하면 호전되는 경우가 많습니다.\n",
      "8.1.[4] 입장료는 무료이지만 사전 예약을 권장합니다 .[5] 7.[1] 시카고에는 세계적으로 유명한 예술 박물관, 미술관, 공원, 호수, 대학, 스포츠 경기장 등이 있습니다.\n",
      "그레이엄의 수제자인 워런 버핏도 이 같은 행동주의 전략을 적극 활용했다.[2] 적극적으로 행사해 그 차이를 빠르게 줄이는 전략이다.이후 행동주의는 1980~1990년대 ‘기업 사냥꾼 시대’를 거쳐 2000년대 들어 헤지펀드의 다양한 투자 전략 중 하나로 자리잡았다.버핏의 일본 종합상사 주식 보유 비중은 점차 늘어 최근에는 7.4%까지 늘어난 것으로 알려졌다.한편 버핏은 최근 지분을 축소한 중국 전기차 업체 비야디(BYD)와 대만 반도체 업체 TSMC에 대해서는 여전히 기업가치를 높게 평가하고 있다고 밝혔습니다.\n",
      "[1] 이 영화가 지속적으로 어필하는 또 다른 이유는 이 영화의 역사적 중요성입니다.[3] 그는 부하들이 육체 노동 프로젝트에 참여하는 것을 거부하고 일본 수용소 사령관 사이토 대령(Sessue Hayakawa)을 화나게 합니다.콰이강의 다리는 실제 사건에 기반을 두고 있으며, 오늘날에도 여전히 관련이 있는 역사의 시기를 엿볼 수 있습니다.그것은 전쟁의 참혹함과 과거의 실수로부터 배우는 것의 중요성을 상기시켜 주는 역할을 합니다.[2] 콰이 강의 다리는 엄청난 역경 속에서도 용기와 결단의 서사시다.그것은 전쟁의 공포와 회복력과 지구력을 일깨워주는 강력한 사건이다.이 영화는 모든 연령대의 관객들을 계속 사로잡고 있는 시대를 초월한 고전으로 역경 속에서도 희망과 끈기의 메시지는 개봉 당시와 마찬가지로 오늘날에도 의미가 있다.\n",
      "일반적으로 봄과 가을에 재배되며 겨울철에는 온실에서 재배할 수도 있습니다.토마토 재배를 위해 필요한 것은 적절한 재배 공간, 씨앗, 토양, 물, 영양소 등입니다.아래는 토마토를 재배하는 방법입니다.< 재배시기와 재배방법 > 토마토는 따뜻한 기후에서 재배되며 적어도 최저 온도가 10℃ 이상인 환경에서 재배하는 것이 적합합니다.[3] 하지만 이러한 부작용은 일반적으로 드물게 발생하며 토마토를 적당히 섭취하는 것이 중요합니다.\n",
      "[2] 일반 상대성 일반 상대성 이론은 1915년 알버트 아인슈타인이 제안한 물리학의 기본 이론입니다.[1] 일반 상대성 일반 상대성 이론은 1915년 알버트 아인슈타인이 제안한 물리학의 기본 이론입니다.중력의 거동과 중력이 시공간 기하학에 미치는 영향을 설명합니다.이 이론은 현대 물리학의 초석이며 우주에 대한 우리의 이해 발전에 엄청난 영향을 미쳤습니다.기본 개념들: 미분 기하학 : 일반 상대성 이론은 미분 기하학이라는 수학적 도구를 사용합니다.\n",
      "[2] 그는 1985년 9월 19일 대한민국 대전에서 태어났습니다.송중기는 2008 년 드라마 '칼을 잡아라!송중기는 송혜교와 2016년 드라마 <태양의 후예>에서 만나 결혼하게 되었으며, 1년 8개월만에 파경을 하게 됩니다.[3] 송중기는 2008년 MBC의 오디션 프로그램 '쇼박스'에서 우승하여 연기자로서의 데뷔를 시작했습니다.오수정'으로 데뷔했다.\n",
      "<죠스>로 헐리우드 영화 사상 처음으로 흥행 수익 1억 달러를 기록하며 블록버스터란 용어를 만들어낸 인물 역시 스티븐 스필버그다.[4] 1946년에 미국에서 태어났으며, 그의 대표작으로는 '죠스' (1975), 'E.T.[3] 1946년에 미국에서 태어났으며, 그의 대표작으로는 '죠스' (1975), 'E.T.[2] 그는 20세기 후반부터 21세기 초반까지 많은 작품을 제작하였으며 전 세계적으로 인정받고 있다.Steven Spielberg는 역사상 가장 위대하고 영향력 있는 영화 제작자 중 한 명으로 널리 알려진 미국 영화 감독, 프로듀서 및 시나리오 작가입니다.\n",
      "[2] '스위스 베른대 병원 심전도 측정 통한 코호트 연구 국내 기업 '에이티센스' 심전도 검사기 활용 해발고도 8849m의 세계 최고봉 에베레스트산을 오르면 부정맥 발생률이 올라갈까?이를 검증하기 위한 임상이 국산 패치형 심전도 검사기를 활용해 이뤄진다.원정대의 발길을 팔로우한 다큐멘터리 방송 및 이후 영화 ‘히말라야’가 제작되어 관객 약 770만 명을 동원하기도 했다.원정대의 발길을 팔로우한 다큐멘터리 방송 및 이후 영화 `히말라야`가 제작돼 관객 약 770만 명을 동원하기도 했다.[4] `휴먼원정대`는 당시 세계 산악 역사 최초로 8000m 고도에서 동료 시신을 거두기 위한 에베레스트 등반으로 화제를 모았었다.\n",
      "평균적으로 남극이 북극보다 더 추운 곳입니다 .남극의 대륙은 해발고도가 높아서 기온이 매우 낮습니다 .남극은 평균 영하 50도에서 영하 20도 사이로 매우 춥습니다.[5] 남극 대륙에 위치한 남극은 평균 기온이 -50°C에서 -20°C 사이로 훨씬 더 추운 온도를 경험합니다.[2] 2.\n",
      "[4] 아마존의 CEO 아마존의 현재 CEO는 제프 베조스입니다.베조스는 아마존을 처음 시작할 때 온라인 서적 판매 회사로 시작했지만, 이후에는 거대한 인터넷 소매 회사로 성장시켰습니다.제프 베조스는 1964년 뉴 멕시코 주 알버커키에서 태어나, 프린스턴 대학교에서 전기공학과 컴퓨터 공학을 전공했습니다.[1] 아마존의 창시자 제프 베조스(1964~현재) 제프 베조스는 아마존의 창업자이자 현재는 CEO에서 퇴직 했지만 여전히 대주주인 창업자 입니다.그는 이를 위해 1995년 아마존을 창업하였으며, 이후 약 26년 동안 회사를 성장시켰습니다.\n",
      "[1] 오프사이드란 무엇인가요?공과 마지막 수비수보다 상대 팀의 골에 더 가까우면 오프사이드 위치에 있게 된다.이 경우 공격하는 팀은 오프사이드라고 하며, 경고 카드와 함께 반칙 판정됩니다.[3] 넷째, 오프사이드이다.만약 선수가 오프사이드 상태에서 활동적인 플레이에 관여한다면, 플레이는 중단되고, 상대팀은 프리킥을 받는다.\n",
      "바이올리니스트가 될 수 없었던 차이코프스키는 바이올린 독주 부분에서는 코테크에게 조언을 구했다.[3] 1887년 차이코프스키는 유럽과 미국을 순회하며 자신의 음악을 지휘하고 광범위한 찬사를 받았습니다.개인 생활 차이코프스키는 사생활에 대해 사적인 것으로 유명했지만, 성적인 문제로 어려움을 겪었고 남성과 여러 차례 연애 관계를 맺은 것으로 알려져 있습니다.[1] 차이코프스키의 바이올린 협주곡 D 장조는 그의 작품 가운데 가장 잘 알려진 작품 중의 하나로 연주에 어려움이 있기로 정평이 난 작품이다.차이코프스키는 안토니오 이바노바 밀루코바와의 비극적 결혼에서 얻은 우울증을 치료하기 위하여 자신의 제자이었던 바이올리스트 요시프 코테크(Yosif Kotek)외 2 명의 학생들을 동반하여 1878년 스위스의 제네바 호숫가에 위치한 휴양지 클라렌스에서 머물렀는데, 이 협주곡은 이때에 작곡되었다.\n",
      "* 연화증이란?이로 인해 골절, 뼈 연화증 등이 발생할 수 있습니다.뿐만 아니라 임산부의 경우 태아의 뼈 성장에도 영향을 줄 수 있고 비타민 d는 우리 몸에 꼭 필요한 영양소입니다.[3] 이는 평균 체중의 사람과 같은 양의 비타민 d를 섭취하여도 체내 농도가 현저히 낮게 검출된다고 합니다.[5] 뼈 관련 증상 비타민 D 부족으로 인해 칼슘과 인의 흡수가 어려워지면 뼈 건강에 영향을 미칩니다.\n",
      "[2] 식물의 장점은 매우 다양합니다.또한 , 영양분도 필요하기 때문에 토양도 중요한 역할을 합니다 .[4] 2.가장 대표적인 것은 산소 생산과 이산화탄소 흡수를 통해 지구 환경을 개선하는 역할을 하는 것입니다.활발한 광합성 작용을 위해서 사람은 에너지원을 밖에서 음식을 섭취하면서 얻게 됩니다.\n",
      "이 영화는 빅토리아 시대를 배경으로 한다.이 영화는 1938년 등장한 스릴러 연극을 리메이크한 것으로, 1940년 영국에서 먼저 리메이크하기도 하였다.가스라이팅은 1938년 패트릭 해밀턴 작가가 연출한 연극인 <가스등>에서 처음 유래가 되었다고 합니다.패트릭 해밀턴 작가가 연출한 스릴러 연극인데 정신적 학대 를 다룬 이야기이며 부부간의 가스라이팅을 주제를 다루게 됩니다.이 연극은 잭이라는 남성이 자기 아내인 벨라를 억압하는 이야기를 담고 있는데요.\n",
      "[2] 자치구, 공사·공단에 대한 지원 예산의 65%도 조기 지원합니다.[4] 서울시가 대중교통 요금을 인상하겠다고 나선 것은 고질적인 적자 문제 때문이다.물가와 인건비 상승 등에도 요금이 동결되면서 적자가 불어나는 추세다.응답자들의 68.3%는 현 대중교통 요금도 부담되는 수준이라고 밝혔다.또 출퇴근 또는 이동 시 주로 이용하는 교통수단은 ▲지하철, 버스(72.4%)가 가장 많았다.\n",
      "[4] 한국의 유네스코 세계문화유산으로 등재된 사적들의 이유에 대해 자세히 설명해드릴께요.인조 12년인 1634년에 문을 연 논산 돈암서원은 조선 중기 유학자 사계 김장생을 기리기 위해 제자들이 세웠다.송준길과 송시열 등 뛰어난 학자들을 배출하면서 기호학파를 대표하는 서원이 되었다.경주역사유적지구 (2000) - 경주는 고대 신라왕조의 수도였던 장소로, 고분군, 사찰, 궁궐 등 수많은 고고적 유적을 보유하고 있습니다.창덕궁과 창경궁 경복궁과 종묘 (1997) - 이곳은 조선시대에 건립된 궁궐과 종묘로, 그 독특한 건축양식과 조경을 통해 조선시대의 전통문화를 대표하는 유산으로 평가되었습니다.\n",
      "알베르트 아인슈타인의 삶과 경력 알베르트 아인슈타인은 1879년 독일의 울름에서 태어났습니다.하지만, 그는 반항적인 성격 때문에 전통적인 교육방식에서 어려움을 겪었습니다.그는 1879년 독일에서 태어났고 어린 나이부터 수학과 과학에 깊은 관심을 보였습니다.[3] 그의 이론과 발견은 전 세계적으로 인정받았으며, 그는 노벨 물리학상을 수상하였습니다.그는 광전효과를 설명한 연구를 통해 1921년 노벨 물리학상을 수상하였으며, 상대성 이론 개발과 양자역학의 발전에 큰 역할을 하였습니다.\n",
      "출생과 성장 그리고 경력 마이클은 1958년 8월 29일 인디애나 주 게리에서 열 자녀 중 여덟 번째로 태어났습니다.출생과 성장 그리고 경력 마이클은 1958년 8월 29일 인디애나 주 게리에서 열 자녀 중 여덟 번째로 태어났습니다.[2] 서태지가 대한민국의 문화 대통령이었다면 마이클 잭슨은 전 세계의 지배자였습니다.[3] 서태지가 대한민국의 문화 대통령이었다면 마이클 잭슨은 전 세계의 지배자였습니다.그는 1960년대 중반에 결성된 가족 밴드인 잭슨 5의 멤버로 어린 나이에 음악 경력을 시작했습니다.\n",
      "도시바는 하드디스크가 유명하며 HDD 및 외장하드, POS, 프린팅 솔루션, 노트북, 반도체 등을 판매하고 있습니다.도시바는 1875년에 설립된 일본의 전기기기 회사입니다.[1] 따라서 도시바의 미래에 대해서는 긍정적인 전망도 나오고 있습니다.[2] 1875년에 설립된 일본의 전기기기 회사인 '도시바'는 일본을 대표하는 기업 중 하나입니다.도시바는 30년전인 1980년대~1990년대까지만 해도 일본의 대표적인 반도체 기업이었습니다.\n",
      "참고사이트 1.구강 위생에 특별한 관심을 기울여야 합니다.[2] 고려해야 할 몇 가지 중요한 사항은 다음과 같습니다.훈련: 강아지는 집 훈련, 목줄 매기 등 기본적인 명령과 매너를 배우도록 훈련을 받아야 합니다.셋째 포메라니안은 훈련이 중요하며, 훈련 과정에서 꼭 보상과 칭찬을 사용하는 것이 좋습니다!\n",
      "궁전은 복잡한 목조 건축, 곡선형 지붕, 아름다운 정원이 특징입니다.일본 건축 일본 건축은 중국과 한국 건축의 영향을 많이 받았지만 수세기 동안 독특한 스타일.이 궁궐은 조선 시대의 유교적 원리를 반영하도록 디자인되었습니다.이는 질서, 계급, 조화의 중요성을 강조하는 것이었습니다.[2] 가장 유명한 예 중 하나 한국 전통 건축의 대표적인 건축물은 14세기 조선시대에 지어진 경복궁입니다.\n",
      "여권 및 비자 유럽으로의 여행을 준비할 때는 반드시 여권과 비자를 확인해야 합니다 .한국 국적의 여행자들은 유럽 대부분의 국가에서 90 일 이내의 비자 없이 방문할 수 있지만 , 몇몇 국가는 비자가 필요할 수 있습니다 .본인이 원하는 일정을 넣으면 다른 사람이 확인하고 일정을 조율했다.[2] 숙소와 기차, 버스를 수소문해서 예약을 했고, 파리와 니스의 일정을 특별히 신경써서 여행 계획을 세웠다.구글 미츠를 켜두고 구글 문서 에서 여행 계획을 함께 작성해나갔다.\n",
      "[2] 코로나 바이러스는 인체에 침투하여 호흡기 감염을 일으키는 바이러스입니다.이 바이러스는 감염자의 비말, 침 등을 통해 전파됩니다.이 바이러스는 호흡기를 통해 전파되며, 감염된 사람은 증상이 없거나 경증인 경우가 많습니다.이 바이러스는 감염된 사람이 말을 하거나 기침을 하거나 재채기를 할 때 주로 호흡기 비말을 통해 전파된다.[3] 코로나 숙주 너구리 코로나바이러스감염증 (COVID-19)은 SARS-CoV-2 바이러스에 의해 인간에게 전염됩니다.\n",
      "이후 수익성 등을 이유로 사업을 접었다가 지난해 3월 북미와 유럽에 처음으로 OLED 제품을 출시했다.[4] 삼성이 국내 시장에 OLED 제품을 내놓은 건 처음이다.10년 전인 2013년 첫 OLED TV 제품을 선보였지만, 지금과는 방식이 다른 패널이었다.[1] 삼성전자는 2006년 '보르도', 2009년 'LED TV', 2011년 '스마트TV' 등을 선보였고, 2017년부터는 퀀텀닷 기술을 적용한 QLED를 내놨다.2018년에는 'QLED 8K', 2021년 퀀텀 미니 LED 기반의 'Neo QLED'와 스스로 빛과 색을 모두 내는 '마이크로 LED'를 처음으로 선보였다.\n",
      "프랑스어(French) Je t'aime !사랑 해!예문에서 입력한 Je t'aime는 사랑해라는 의미인데요.[4] 4.[1] 한번 배우고나면 비슷한 언어들인 유럽지방은 쉽게 배워볼수 있다고 합니다.\n",
      "[2] 공차는 7가지 토핑이 있어,각 메뉴에 추가하실 수 있습니다.소금, 후추, 치즈 등을 뿌려 간을 맞춰 먹으면 더욱 맛있습니다.동남아 국가들에서도 간단한 주전부리나 술안주로 인기가 높다고 하는데요.[3] 카사바칩은 카사바를 얇게 썰어 구운 칩으로 만들어 먹을 수 있습니다.타피오카는 점성이 커서 국수나 밀가루 음식에 넣어 먹기도 합니다.\n",
      "마일(mile) : 영미권에서 사용되는 길이의 단위로, 1마일은 약 1.6093km입니다.[1] 야드(yard): 영미권에서 사용되는 길이의 단위로, 1야드는 약 91.44cm입니다.[3] 원마일 웨어란?이 외에도 각 나라마다 독자적인 길이의 단위를 사용하기도 합니다.(one-mile wear) 실내와 집 근처 1마일(1.6km) 반경 내에서 입을 수 있는 옷으로, 집 근처를 산책하는 등 가벼운 외출 시 활용할 수 있다는 점이 특징이다.\n",
      "2009년 1월 3일에 비트코인이 처음 발행되었으며 2009년 12월 11일에 프로그림이 공개되었다.이 논문에서 사토시는 분산화된 디지털 화폐 시스템에 대한 개념을 제안하였습니다.장점 비트코인의 가장 큰 특징은 관리주체가 정해져 있지 않음에도 불구하고 작동한다는 점입니다.[3] '비트코인'이라는 명칭은 컴퓨터의 단위를 뜻하는 비트(Bit)와 화폐를 뜻하는(Coin)에서 유래되었다.사토시 나카모토에 의해 2008년 10월에 'Bit coin: A Peer-to-Peer Electronic Cash System'이라는 제목의 9쪽짜리 논문을 통해 공개되었다.\n",
      "[2] 진돗개는 강아지의 품종 중 하나입니다 .충성심 , 지능 및 독립성으로 알려진 중형견입니다 .한국의 토종 품종 중 하나이며 용감하고 충성심이 강해 주인을 잘 따른다고 합니다 .[1] 1.진돗개에 대해 알고 싶어요.한국 진도 또는 진도 개라고도 알려진 진돗개는 한국의 진도 섬에서 유래한 사냥개 품종입니다 .\n",
      "5.쇠고기, 돼지고기, 닭고기 등의 동물성 단백질은 필수 아미노산이 풍부합니다.[2] 단백질이 풍부하게 함유된 식품에는 어떤 것들이 있을까요?[4] 동물성 단백질 공급 식품으로는 계란, 치즈, 연어, 닭가슴살, 소고기, 우유 등이 있다.참고로 계란 1개 단백질 함량은 7g이다.\n",
      "AI 발전은 그래픽처리장치(GPU), 신경망처리장치(NPU) 등 반도체의 발전으로 이뤄졌다.그러므로 새로운 애플리케이션의 성장은 AI칩 수요에 긍정적인 영향을 끼칠 수밖에 없다.이 장치는 AI나 고성능컴퓨터(HPC)에 들어가 연산 속도를 높이는 역할을 한다.저는 개인적으로 구글을 응원하고 싶어요.미국의 제재에도 첨단 반도체 개발을 위해 노력하고 있다는 것이다.\n",
      "중국은 그간 코로나19 바이러스가 동물이 아닌 인간에서 시작됐다는 입장이었다.세계보건기구(WHO)는 중국이 코로나와 야생동물 간 연관성을 더 일찍 공유했어야 됐다고 비판했다.[3] 중국 우한의 수산시장에서 불법 거래된 너구리가 코로나바이러스감염증(코로나) 숙주일 가능성이 제기됐다.코로나19가 정체불명의 폐렴으로 처음 보고됐을 때 WHO는 화난 시장을 최초 발병지로 지목한 바 있다.[1] 코로나19는 중국 우한에서 처음으로 집단 감염이 발병했으며, 2019년 12월 세계보건기구(WHO)에 정체불명 폐렴으로 처음 보고됐을 때 우한의 화난 수산시장이 발병지로 지목됐다.\n",
      "[5] \"찰나의 빛에 영혼을 담다.\"모네는 '인상주의' 화풍의 창시자로 알려져 있지요.그는 인상주의 운동의 중심 인물 중 하나였으며, 그의 작품은 선명한 색상, 빛과 그림자의 사용, 그리고 흐릿하게 묘사된 풍경으로 유명합니다.▣작가 소개 - 클로드 모네(Claude Monet) 클로드 모네는 프랑스의 유명한 인상주의 화가입니다.[3] 위치: 서울 특별시 중국 남대문로 73 에비뉴엘 9층 클로드 모네(Claude Monet)는 19세기 후반 프랑스의 유명한 화가 중 한 명입니다.\n",
      "[2] 마크 주커버그 그는 누구인가?이 사이트는 현재 전 세계적으로 이용되는 가장 대표적인 소셜 네트워킹 사이트로 자리 잡았습니다.컴퓨터와 프로그래밍에 대한 저커버그의 관심은 어린 나이에 시작되었다.[4] 생애 업적 마크 주커버그는 1984년 5월 14일 미구 뉴욕주 노스암프턴에서 태어난 기업가이며, 페이스북의 창업자이자 CEO입니다.[1] 마크 주커버그는 세계에서 가장 큰 소셜 미디어 플랫폼 중 하나인 페이스북을 공동 설립한 것으로 가장 잘 알려진 미국의 기업가이자 소프트웨어 개발자이다.\n",
      "확률 분포에서 중앙값을 기준으로 양쪽의 넓이 또한 같아야 하지요.[4] 그런 극단값이 존재할 때는 평균보다는 중앙값을 사용한다.최빈값은 가장 많이 나타나는 값을, 중앙값은 데이터의 순서상 가운데에 있는 값을 의미합니다.데이터의 개수가 짝수인 경우는, 가운데에 오는 2 개의 값의 평균을 취합니다.그래서 극단값과 같은 이상치에 영향을 받지 않게 된다.\n",
      "[3] 르네상스 시대를 대표하는 예술가로 우리는 미켈란젤로를 뽑습니다.르네상스 대표 화가 <산드로 보티첼리> 산드로 보티첼리는 르네상스 시대를 대표하는 이탈리아 화가입니다.미켈란젤로는 이탈리아 르네상스 시대의 대표적인 예술가중 한 명으로, 조각과 회화 분야에서 활동하였습니다.[2] 2.[5] 이러한 발전은 유럽 문화의 발전과 함께 세계문화에 큰 영향을 미쳤습니다 .\n",
      "ISO 14001인증은 자연친화적 생산시스템 구축, 운영, 평가, 관리가 유지되고 있음을 내포하는 국제 인증이다.[3] 라닉스가 획득한 ISO 9001은 국제표준화기구(이하 ISO)에서 제정한 품질경영시스템에 대한 국제규격이다.품질 경영에 규정된 요구사항을 만족하고 지속적으로 관리하고 있음을 국제적으로 인증한다는 의미다.[1] 또 지난해 말에는 FCC 인증(전자파, 전파 규제기준 충족)을 갱신하고 ISO 45001(환경 경영) 인증 등을 취득했다.ISO 9001은 품질경영시스템 국제 규격으로 소비자에게 전달되는 서비스의 전 과정이 국내뿐만 아니라 국제 기준에도 부합함을 입증하는 기준이다.\n",
      "[2] 연방준비제도의 역할은 무엇인가?연방준비제도 즉 FED의 역할은 시장의 수요와 공급을 결정하는 역할을 합니다.[1] 연방준비제도, 종종 연준이라고도 불리는 연방준비제도는 미국의 중앙은행입니다.연준에는 통화 공급과 금리에 영향을 미치는 세 가지 주요 정책 도구가 있습니다.1913년 연방준비제도법에 의해 창설되었으며 통화정책 수행, 은행 감독 및 규제, 금융시스템의 안정성 유지 등을 담당하고 있습니다.\n",
      "여성 바둑 기사들의 부상과 그들이 바둑 게임에 미치는 영향을 살펴본다.[1] 중국 바둑의 역사 바둑은 2,500 년 전 춘추전국시대에 중국에 소개되었다 .19x19 그리드로 진행되며, 가능한 한 많은 영토를 포위하고 점령하는 것이 게임의 목적이다.바둑은 지식인들을 위한 게임으로 생각되었고 학자들과 귀족들에 의해 행해졌다 .오랜 역사를 가진 남성 위주의 게임이지만, 최근에는 이 게임에서 두각을 나타내고 있는 여성 바둑 기사들이 증가하고 있다.\n",
      "[3] 에펠탑은 파리에서 가장 유명한 지형학적 랜드마크 중 하나입니다.이 건축물은 1889년에 완성되었으며, 원래는 20년간 지속될 계획이었습니다.[1] 에펠탑 엘리베이터 기타 사항 1.1889년에 지어진 이 철탑은 높이가 324미터이고 전망대에서 도시의 멋진 전망을 제공합니다.방문객들은 계단이나 엘리베이터를 타고 꼭대기까지 올라가 타워의 식당 중 하나에서 식사를 즐길 수 있습니다.\n",
      "[3] 반도체는 ‘8대 공정’을 통해 제조된다.반도체 생산 과정은 크게 설계-웨이퍼 생산-패키징 및 테스트 등 3단계에 걸쳐 진행된다.[2] 높은 수율을 얻기 위해서는 공정 장비의 정확도와 클린룸의 청정도, 공정 조건 등 여러 제반 사항이 뒷받침돼야 한다.그중에서도 가장 기초가 되는 것이 웨이퍼(Wafer·원판) 제조 공정이다.2019년부터 미국의 반도체 제재가 본격화되면서 중국은 반도체 장비, 소재 확보에 어려움을 겪어왔습니다.\n",
      "세계에서 일류 와인 양조지가 가장 많은 와인 산지입니다.[1] < 지역별 와인의 특징 > 프랑스의 주요 와인 생산지역으로는 보르도, 부르고뉴, 로렌 밸리, 코르시카, 샴페인 등이 있습니다.보르도 지역의 와인은 타닌이 많고, 크게 붉은 와인과 흰 와인으로 나뉘어지며, 산미와 바디감이 강합니다.부르고뉴 지역은 피노 누아르와 샤르도네 와인이 유명하며, 가벼우면서도 풍미가 깊습니다.[2] 테이블 와인은 프랑스 와인 생산의 35% 정도를 차지하고 있으며 용기에 알코올 함량만 표기되고 이름이나 원산지 등이 표기되지 않아도 무방합니다.\n",
      "[4] 브라이언 메이(Brian May) : 퀸의 기타리스트로서, 그룹의 음악을 작곡하는 중요한 역할을 합니다.로저 테일러(Roger Taylor) : 퀸의 미모담당 , 노래를 부르기도 합니다.그중에는 'Bohemian Rhapsody', 'Somebody to Love', 'We Are the Champions', 'Don't Stop Me Now' 등이 있다.그는 1980년대 후반 인체 면역 결핍 바이러스 HIV에 감염되어 갑자기 건강이 악화되었다.[2] 프레디는 퀸 밴드의 대표 멤버로서 다양한 히트곡들을 만들어냈다.\n",
      "[2] 나폴레옹 보나파르트(Napoleon Bonaparte)는 누구인가?나폴레옹은 파리 육군사관학교에 재학 중에 육군 포병 소위로 임관하였다.나폴레옹 보나파르트는 프랑스의 황제로서 전쟁, 정치, 문화 등 다양한 분야에서 업적을 남겼습니다.[3] 흔히 나폴레옹(프랑스어: Napoléon, 문화어: 나뽈레옹)으로 불린다.코르시카 섬의 하급 귀족 가문 출신의 군인으로, 프랑스혁명 시기에 벌어진 전쟁에서 큰 공을 세우며 국민적 영웅이 되었고, 쿠데타를 통해 제1 통령이 된 후 종신통령을 거쳐서 황제에 즉위했다.\n",
      "강남성모병원 아시나요?자리도 쾌적하고 서초구에 위치하고 있어서 접근도 편한 편이다.[2] 1.국립중앙도서관 위치 및 교통 국립중앙도서관은 서울시 서초구에 위치합니다.게다가 자율배식이라 원하는 만큼 풀 수 있다.\n",
      "[2] S&P 500 지수는 국제 신용평가기관인 미국의 Standard and Poors (S&P)이 작성한 주가 지수이다.이 지수는 구성 기업의 가중치가 시가 총액을 좀더 정확하게 반영하도록 주기적으로 재조정됩니다.현재 S&P 500에 포함된 몇몇 회사들은 애플, 아마존, 페이스북, 구글 모회사 알파벳과 같은 그들의 산업에서 잘 알려진 거대 기업들이다.[4] 이 지수는 금융 서비스 회사인 Standard & Poor's 에 의해 만들어졌으며 투자자에게 미국 주식 시장의 성과에 대한 광범위한 측정을 제공하기 위한 수단으로 1957 년에 처음 도입되었습니다.[5] 이 지수는 금융 서비스 회사인 Standard & Poor's 에 의해 만들어졌으며 투자자에게 미국 주식 시장의 성과에 대한 광범위한 측정을 제공하기 위한 수단으로 1957 년에 처음 도입되었습니다.\n",
      "에어 조던은 농구 선수뿐만 아니라 일반인들도 스트릿 패션으로 즐겨 신는 인기 있는 슈즈 브랜드 중 하나입니다.1985년에 최초의 에어 조던 신발이 출시되었고 빠르게 문화 현상이 되었습니다.에어 조던 운동화는 마이클 조던을 위해 특별히 고안되었고, 그것들은 빠르게 농구 선수들과 팬들 사이에서 인기를 얻었습니다.에어 조던은 1984년에 최초로 출시되었으며, 이후 매년 새로운 디자인과 색상이 출시되고 있습니다.최초의 에어 조던 신발인 에어 조던 1은 1985년에 출시되었으며 농구 선수와 운동화 애호가들 사이에서 빠르게 인기를 얻었습니다.\n",
      "아인슈타인은 또한 양자 역학 연구와 현대 우주론의 발전에 중요한 기여를 했다.[2] 일반 상대성 일반 상대성 이론은 1915년 알버트 아인슈타인이 제안한 물리학의 기본 이론입니다.[1] 일반 상대성 일반 상대성 이론은 1915년 알버트 아인슈타인이 제안한 물리학의 기본 이론입니다.중력의 거동과 중력이 시공간 기하학에 미치는 영향을 설명합니다.이 원리는 갈릴레오 갈릴레이에 의해 이전에 제안되었고 아인슈타인 이전에 많은 과학자에 의해 실험적으로 확인되었습니다.\n",
      "강한 자외선과 더운 날씨에 외출을 가급적 삼가를 해야 하며 몸으로 빠져나가는 수분을 이온음료, 물 등을 수시로 섭취하여 보충해줘야 합니다.또한, 규칙적으로 물을 마시고 몸에 수분이 부족하지 않도록 주의하는 것도 좋습니다.일사병은 대체적으로 염분과 수분의 부족으로 나타나는 경우가 많으므로 규칙적인 수분 섭취를 통해 예방할 수 있습니다.따라서 부득이하게 야외에 나갈 때는 챙이 넓은 모자를 쓰고 헐렁한 옷을 입는 것이 좋습니다.일시적으로 일사병의 증상이 나타나는 경우 서늘한 곳에서 휴식을 취하고 수분을 섭취하면 호전되는 경우가 많습니다.\n",
      "8.1.[4] 입장료는 무료이지만 사전 예약을 권장합니다 .[5] 7.[1] 시카고에는 세계적으로 유명한 예술 박물관, 미술관, 공원, 호수, 대학, 스포츠 경기장 등이 있습니다.\n",
      "그레이엄의 수제자인 워런 버핏도 이 같은 행동주의 전략을 적극 활용했다.[2] 적극적으로 행사해 그 차이를 빠르게 줄이는 전략이다.이후 행동주의는 1980~1990년대 ‘기업 사냥꾼 시대’를 거쳐 2000년대 들어 헤지펀드의 다양한 투자 전략 중 하나로 자리잡았다.버핏의 일본 종합상사 주식 보유 비중은 점차 늘어 최근에는 7.4%까지 늘어난 것으로 알려졌다.한편 버핏은 최근 지분을 축소한 중국 전기차 업체 비야디(BYD)와 대만 반도체 업체 TSMC에 대해서는 여전히 기업가치를 높게 평가하고 있다고 밝혔습니다.\n",
      "[1] 이 영화가 지속적으로 어필하는 또 다른 이유는 이 영화의 역사적 중요성입니다.[3] 그는 부하들이 육체 노동 프로젝트에 참여하는 것을 거부하고 일본 수용소 사령관 사이토 대령(Sessue Hayakawa)을 화나게 합니다.콰이강의 다리는 실제 사건에 기반을 두고 있으며, 오늘날에도 여전히 관련이 있는 역사의 시기를 엿볼 수 있습니다.그것은 전쟁의 참혹함과 과거의 실수로부터 배우는 것의 중요성을 상기시켜 주는 역할을 합니다.[2] 콰이 강의 다리는 엄청난 역경 속에서도 용기와 결단의 서사시다.그것은 전쟁의 공포와 회복력과 지구력을 일깨워주는 강력한 사건이다.이 영화는 모든 연령대의 관객들을 계속 사로잡고 있는 시대를 초월한 고전으로 역경 속에서도 희망과 끈기의 메시지는 개봉 당시와 마찬가지로 오늘날에도 의미가 있다.\n",
      "일반적으로 봄과 가을에 재배되며 겨울철에는 온실에서 재배할 수도 있습니다.토마토 재배를 위해 필요한 것은 적절한 재배 공간, 씨앗, 토양, 물, 영양소 등입니다.아래는 토마토를 재배하는 방법입니다.< 재배시기와 재배방법 > 토마토는 따뜻한 기후에서 재배되며 적어도 최저 온도가 10℃ 이상인 환경에서 재배하는 것이 적합합니다.[3] 하지만 이러한 부작용은 일반적으로 드물게 발생하며 토마토를 적당히 섭취하는 것이 중요합니다.\n",
      "[2] 일반 상대성 일반 상대성 이론은 1915년 알버트 아인슈타인이 제안한 물리학의 기본 이론입니다.[1] 일반 상대성 일반 상대성 이론은 1915년 알버트 아인슈타인이 제안한 물리학의 기본 이론입니다.중력의 거동과 중력이 시공간 기하학에 미치는 영향을 설명합니다.이 이론은 현대 물리학의 초석이며 우주에 대한 우리의 이해 발전에 엄청난 영향을 미쳤습니다.기본 개념들: 미분 기하학 : 일반 상대성 이론은 미분 기하학이라는 수학적 도구를 사용합니다.\n",
      "[2] 그는 1985년 9월 19일 대한민국 대전에서 태어났습니다.송중기는 2008 년 드라마 '칼을 잡아라!송중기는 송혜교와 2016년 드라마 <태양의 후예>에서 만나 결혼하게 되었으며, 1년 8개월만에 파경을 하게 됩니다.[3] 송중기는 2008년 MBC의 오디션 프로그램 '쇼박스'에서 우승하여 연기자로서의 데뷔를 시작했습니다.오수정'으로 데뷔했다.\n",
      "<죠스>로 헐리우드 영화 사상 처음으로 흥행 수익 1억 달러를 기록하며 블록버스터란 용어를 만들어낸 인물 역시 스티븐 스필버그다.[4] 1946년에 미국에서 태어났으며, 그의 대표작으로는 '죠스' (1975), 'E.T.[3] 1946년에 미국에서 태어났으며, 그의 대표작으로는 '죠스' (1975), 'E.T.[2] 그는 20세기 후반부터 21세기 초반까지 많은 작품을 제작하였으며 전 세계적으로 인정받고 있다.Steven Spielberg는 역사상 가장 위대하고 영향력 있는 영화 제작자 중 한 명으로 널리 알려진 미국 영화 감독, 프로듀서 및 시나리오 작가입니다.\n",
      "[2] '스위스 베른대 병원 심전도 측정 통한 코호트 연구 국내 기업 '에이티센스' 심전도 검사기 활용 해발고도 8849m의 세계 최고봉 에베레스트산을 오르면 부정맥 발생률이 올라갈까?이를 검증하기 위한 임상이 국산 패치형 심전도 검사기를 활용해 이뤄진다.원정대의 발길을 팔로우한 다큐멘터리 방송 및 이후 영화 ‘히말라야’가 제작되어 관객 약 770만 명을 동원하기도 했다.원정대의 발길을 팔로우한 다큐멘터리 방송 및 이후 영화 `히말라야`가 제작돼 관객 약 770만 명을 동원하기도 했다.[4] `휴먼원정대`는 당시 세계 산악 역사 최초로 8000m 고도에서 동료 시신을 거두기 위한 에베레스트 등반으로 화제를 모았었다.\n",
      "평균적으로 남극이 북극보다 더 추운 곳입니다 .남극의 대륙은 해발고도가 높아서 기온이 매우 낮습니다 .남극은 평균 영하 50도에서 영하 20도 사이로 매우 춥습니다.[5] 남극 대륙에 위치한 남극은 평균 기온이 -50°C에서 -20°C 사이로 훨씬 더 추운 온도를 경험합니다.[2] 2.\n",
      "[4] 아마존의 CEO 아마존의 현재 CEO는 제프 베조스입니다.베조스는 아마존을 처음 시작할 때 온라인 서적 판매 회사로 시작했지만, 이후에는 거대한 인터넷 소매 회사로 성장시켰습니다.제프 베조스는 1964년 뉴 멕시코 주 알버커키에서 태어나, 프린스턴 대학교에서 전기공학과 컴퓨터 공학을 전공했습니다.[1] 아마존의 창시자 제프 베조스(1964~현재) 제프 베조스는 아마존의 창업자이자 현재는 CEO에서 퇴직 했지만 여전히 대주주인 창업자 입니다.그는 이를 위해 1995년 아마존을 창업하였으며, 이후 약 26년 동안 회사를 성장시켰습니다.\n",
      "[1] 오프사이드란 무엇인가요?공과 마지막 수비수보다 상대 팀의 골에 더 가까우면 오프사이드 위치에 있게 된다.이 경우 공격하는 팀은 오프사이드라고 하며, 경고 카드와 함께 반칙 판정됩니다.[3] 넷째, 오프사이드이다.만약 선수가 오프사이드 상태에서 활동적인 플레이에 관여한다면, 플레이는 중단되고, 상대팀은 프리킥을 받는다.\n",
      "바이올리니스트가 될 수 없었던 차이코프스키는 바이올린 독주 부분에서는 코테크에게 조언을 구했다.[3] 1887년 차이코프스키는 유럽과 미국을 순회하며 자신의 음악을 지휘하고 광범위한 찬사를 받았습니다.개인 생활 차이코프스키는 사생활에 대해 사적인 것으로 유명했지만, 성적인 문제로 어려움을 겪었고 남성과 여러 차례 연애 관계를 맺은 것으로 알려져 있습니다.[1] 차이코프스키의 바이올린 협주곡 D 장조는 그의 작품 가운데 가장 잘 알려진 작품 중의 하나로 연주에 어려움이 있기로 정평이 난 작품이다.차이코프스키는 안토니오 이바노바 밀루코바와의 비극적 결혼에서 얻은 우울증을 치료하기 위하여 자신의 제자이었던 바이올리스트 요시프 코테크(Yosif Kotek)외 2 명의 학생들을 동반하여 1878년 스위스의 제네바 호숫가에 위치한 휴양지 클라렌스에서 머물렀는데, 이 협주곡은 이때에 작곡되었다.\n",
      "* 연화증이란?이로 인해 골절, 뼈 연화증 등이 발생할 수 있습니다.뿐만 아니라 임산부의 경우 태아의 뼈 성장에도 영향을 줄 수 있고 비타민 d는 우리 몸에 꼭 필요한 영양소입니다.[3] 이는 평균 체중의 사람과 같은 양의 비타민 d를 섭취하여도 체내 농도가 현저히 낮게 검출된다고 합니다.[5] 뼈 관련 증상 비타민 D 부족으로 인해 칼슘과 인의 흡수가 어려워지면 뼈 건강에 영향을 미칩니다.\n",
      "[2] 식물의 장점은 매우 다양합니다.또한 , 영양분도 필요하기 때문에 토양도 중요한 역할을 합니다 .[4] 2.가장 대표적인 것은 산소 생산과 이산화탄소 흡수를 통해 지구 환경을 개선하는 역할을 하는 것입니다.활발한 광합성 작용을 위해서 사람은 에너지원을 밖에서 음식을 섭취하면서 얻게 됩니다.\n",
      "이 영화는 빅토리아 시대를 배경으로 한다.이 영화는 1938년 등장한 스릴러 연극을 리메이크한 것으로, 1940년 영국에서 먼저 리메이크하기도 하였다.가스라이팅은 1938년 패트릭 해밀턴 작가가 연출한 연극인 <가스등>에서 처음 유래가 되었다고 합니다.패트릭 해밀턴 작가가 연출한 스릴러 연극인데 정신적 학대 를 다룬 이야기이며 부부간의 가스라이팅을 주제를 다루게 됩니다.이 연극은 잭이라는 남성이 자기 아내인 벨라를 억압하는 이야기를 담고 있는데요.\n",
      "[2] 자치구, 공사·공단에 대한 지원 예산의 65%도 조기 지원합니다.[4] 서울시가 대중교통 요금을 인상하겠다고 나선 것은 고질적인 적자 문제 때문이다.물가와 인건비 상승 등에도 요금이 동결되면서 적자가 불어나는 추세다.응답자들의 68.3%는 현 대중교통 요금도 부담되는 수준이라고 밝혔다.또 출퇴근 또는 이동 시 주로 이용하는 교통수단은 ▲지하철, 버스(72.4%)가 가장 많았다.\n",
      "[4] 한국의 유네스코 세계문화유산으로 등재된 사적들의 이유에 대해 자세히 설명해드릴께요.인조 12년인 1634년에 문을 연 논산 돈암서원은 조선 중기 유학자 사계 김장생을 기리기 위해 제자들이 세웠다.송준길과 송시열 등 뛰어난 학자들을 배출하면서 기호학파를 대표하는 서원이 되었다.경주역사유적지구 (2000) - 경주는 고대 신라왕조의 수도였던 장소로, 고분군, 사찰, 궁궐 등 수많은 고고적 유적을 보유하고 있습니다.창덕궁과 창경궁 경복궁과 종묘 (1997) - 이곳은 조선시대에 건립된 궁궐과 종묘로, 그 독특한 건축양식과 조경을 통해 조선시대의 전통문화를 대표하는 유산으로 평가되었습니다.\n",
      "알베르트 아인슈타인의 삶과 경력 알베르트 아인슈타인은 1879년 독일의 울름에서 태어났습니다.하지만, 그는 반항적인 성격 때문에 전통적인 교육방식에서 어려움을 겪었습니다.그는 1879년 독일에서 태어났고 어린 나이부터 수학과 과학에 깊은 관심을 보였습니다.[3] 그의 이론과 발견은 전 세계적으로 인정받았으며, 그는 노벨 물리학상을 수상하였습니다.그는 광전효과를 설명한 연구를 통해 1921년 노벨 물리학상을 수상하였으며, 상대성 이론 개발과 양자역학의 발전에 큰 역할을 하였습니다.\n",
      "출생과 성장 그리고 경력 마이클은 1958년 8월 29일 인디애나 주 게리에서 열 자녀 중 여덟 번째로 태어났습니다.출생과 성장 그리고 경력 마이클은 1958년 8월 29일 인디애나 주 게리에서 열 자녀 중 여덟 번째로 태어났습니다.[2] 서태지가 대한민국의 문화 대통령이었다면 마이클 잭슨은 전 세계의 지배자였습니다.[3] 서태지가 대한민국의 문화 대통령이었다면 마이클 잭슨은 전 세계의 지배자였습니다.그는 1960년대 중반에 결성된 가족 밴드인 잭슨 5의 멤버로 어린 나이에 음악 경력을 시작했습니다.\n",
      "도시바는 하드디스크가 유명하며 HDD 및 외장하드, POS, 프린팅 솔루션, 노트북, 반도체 등을 판매하고 있습니다.도시바는 1875년에 설립된 일본의 전기기기 회사입니다.[1] 따라서 도시바의 미래에 대해서는 긍정적인 전망도 나오고 있습니다.[2] 1875년에 설립된 일본의 전기기기 회사인 '도시바'는 일본을 대표하는 기업 중 하나입니다.도시바는 30년전인 1980년대~1990년대까지만 해도 일본의 대표적인 반도체 기업이었습니다.\n",
      "참고사이트 1.구강 위생에 특별한 관심을 기울여야 합니다.[2] 고려해야 할 몇 가지 중요한 사항은 다음과 같습니다.훈련: 강아지는 집 훈련, 목줄 매기 등 기본적인 명령과 매너를 배우도록 훈련을 받아야 합니다.셋째 포메라니안은 훈련이 중요하며, 훈련 과정에서 꼭 보상과 칭찬을 사용하는 것이 좋습니다!\n",
      "궁전은 복잡한 목조 건축, 곡선형 지붕, 아름다운 정원이 특징입니다.일본 건축 일본 건축은 중국과 한국 건축의 영향을 많이 받았지만 수세기 동안 독특한 스타일.이 궁궐은 조선 시대의 유교적 원리를 반영하도록 디자인되었습니다.이는 질서, 계급, 조화의 중요성을 강조하는 것이었습니다.[2] 가장 유명한 예 중 하나 한국 전통 건축의 대표적인 건축물은 14세기 조선시대에 지어진 경복궁입니다.\n",
      "여권 및 비자 유럽으로의 여행을 준비할 때는 반드시 여권과 비자를 확인해야 합니다 .한국 국적의 여행자들은 유럽 대부분의 국가에서 90 일 이내의 비자 없이 방문할 수 있지만 , 몇몇 국가는 비자가 필요할 수 있습니다 .본인이 원하는 일정을 넣으면 다른 사람이 확인하고 일정을 조율했다.[2] 숙소와 기차, 버스를 수소문해서 예약을 했고, 파리와 니스의 일정을 특별히 신경써서 여행 계획을 세웠다.구글 미츠를 켜두고 구글 문서 에서 여행 계획을 함께 작성해나갔다.\n",
      "[2] 코로나 바이러스는 인체에 침투하여 호흡기 감염을 일으키는 바이러스입니다.이 바이러스는 감염자의 비말, 침 등을 통해 전파됩니다.이 바이러스는 호흡기를 통해 전파되며, 감염된 사람은 증상이 없거나 경증인 경우가 많습니다.이 바이러스는 감염된 사람이 말을 하거나 기침을 하거나 재채기를 할 때 주로 호흡기 비말을 통해 전파된다.[3] 코로나 숙주 너구리 코로나바이러스감염증 (COVID-19)은 SARS-CoV-2 바이러스에 의해 인간에게 전염됩니다.\n",
      "이후 수익성 등을 이유로 사업을 접었다가 지난해 3월 북미와 유럽에 처음으로 OLED 제품을 출시했다.[4] 삼성이 국내 시장에 OLED 제품을 내놓은 건 처음이다.10년 전인 2013년 첫 OLED TV 제품을 선보였지만, 지금과는 방식이 다른 패널이었다.[1] 삼성전자는 2006년 '보르도', 2009년 'LED TV', 2011년 '스마트TV' 등을 선보였고, 2017년부터는 퀀텀닷 기술을 적용한 QLED를 내놨다.2018년에는 'QLED 8K', 2021년 퀀텀 미니 LED 기반의 'Neo QLED'와 스스로 빛과 색을 모두 내는 '마이크로 LED'를 처음으로 선보였다.\n",
      "프랑스어(French) Je t'aime !사랑 해!예문에서 입력한 Je t'aime는 사랑해라는 의미인데요.[4] 4.[1] 한번 배우고나면 비슷한 언어들인 유럽지방은 쉽게 배워볼수 있다고 합니다.\n",
      "[2] 공차는 7가지 토핑이 있어,각 메뉴에 추가하실 수 있습니다.소금, 후추, 치즈 등을 뿌려 간을 맞춰 먹으면 더욱 맛있습니다.동남아 국가들에서도 간단한 주전부리나 술안주로 인기가 높다고 하는데요.[3] 카사바칩은 카사바를 얇게 썰어 구운 칩으로 만들어 먹을 수 있습니다.타피오카는 점성이 커서 국수나 밀가루 음식에 넣어 먹기도 합니다.\n",
      "마일(mile) : 영미권에서 사용되는 길이의 단위로, 1마일은 약 1.6093km입니다.[1] 야드(yard): 영미권에서 사용되는 길이의 단위로, 1야드는 약 91.44cm입니다.[3] 원마일 웨어란?이 외에도 각 나라마다 독자적인 길이의 단위를 사용하기도 합니다.(one-mile wear) 실내와 집 근처 1마일(1.6km) 반경 내에서 입을 수 있는 옷으로, 집 근처를 산책하는 등 가벼운 외출 시 활용할 수 있다는 점이 특징이다.\n",
      "2009년 1월 3일에 비트코인이 처음 발행되었으며 2009년 12월 11일에 프로그림이 공개되었다.이 논문에서 사토시는 분산화된 디지털 화폐 시스템에 대한 개념을 제안하였습니다.장점 비트코인의 가장 큰 특징은 관리주체가 정해져 있지 않음에도 불구하고 작동한다는 점입니다.[3] '비트코인'이라는 명칭은 컴퓨터의 단위를 뜻하는 비트(Bit)와 화폐를 뜻하는(Coin)에서 유래되었다.사토시 나카모토에 의해 2008년 10월에 'Bit coin: A Peer-to-Peer Electronic Cash System'이라는 제목의 9쪽짜리 논문을 통해 공개되었다.\n",
      "[2] 진돗개는 강아지의 품종 중 하나입니다 .충성심 , 지능 및 독립성으로 알려진 중형견입니다 .한국의 토종 품종 중 하나이며 용감하고 충성심이 강해 주인을 잘 따른다고 합니다 .[1] 1.진돗개에 대해 알고 싶어요.한국 진도 또는 진도 개라고도 알려진 진돗개는 한국의 진도 섬에서 유래한 사냥개 품종입니다 .\n",
      "5.쇠고기, 돼지고기, 닭고기 등의 동물성 단백질은 필수 아미노산이 풍부합니다.[2] 단백질이 풍부하게 함유된 식품에는 어떤 것들이 있을까요?[4] 동물성 단백질 공급 식품으로는 계란, 치즈, 연어, 닭가슴살, 소고기, 우유 등이 있다.참고로 계란 1개 단백질 함량은 7g이다.\n",
      "AI 발전은 그래픽처리장치(GPU), 신경망처리장치(NPU) 등 반도체의 발전으로 이뤄졌다.그러므로 새로운 애플리케이션의 성장은 AI칩 수요에 긍정적인 영향을 끼칠 수밖에 없다.이 장치는 AI나 고성능컴퓨터(HPC)에 들어가 연산 속도를 높이는 역할을 한다.저는 개인적으로 구글을 응원하고 싶어요.미국의 제재에도 첨단 반도체 개발을 위해 노력하고 있다는 것이다.\n",
      "중국은 그간 코로나19 바이러스가 동물이 아닌 인간에서 시작됐다는 입장이었다.세계보건기구(WHO)는 중국이 코로나와 야생동물 간 연관성을 더 일찍 공유했어야 됐다고 비판했다.[3] 중국 우한의 수산시장에서 불법 거래된 너구리가 코로나바이러스감염증(코로나) 숙주일 가능성이 제기됐다.코로나19가 정체불명의 폐렴으로 처음 보고됐을 때 WHO는 화난 시장을 최초 발병지로 지목한 바 있다.[1] 코로나19는 중국 우한에서 처음으로 집단 감염이 발병했으며, 2019년 12월 세계보건기구(WHO)에 정체불명 폐렴으로 처음 보고됐을 때 우한의 화난 수산시장이 발병지로 지목됐다.\n",
      "[5] \"찰나의 빛에 영혼을 담다.\"모네는 '인상주의' 화풍의 창시자로 알려져 있지요.그는 인상주의 운동의 중심 인물 중 하나였으며, 그의 작품은 선명한 색상, 빛과 그림자의 사용, 그리고 흐릿하게 묘사된 풍경으로 유명합니다.▣작가 소개 - 클로드 모네(Claude Monet) 클로드 모네는 프랑스의 유명한 인상주의 화가입니다.[3] 위치: 서울 특별시 중국 남대문로 73 에비뉴엘 9층 클로드 모네(Claude Monet)는 19세기 후반 프랑스의 유명한 화가 중 한 명입니다.\n",
      "[2] 마크 주커버그 그는 누구인가?이 사이트는 현재 전 세계적으로 이용되는 가장 대표적인 소셜 네트워킹 사이트로 자리 잡았습니다.컴퓨터와 프로그래밍에 대한 저커버그의 관심은 어린 나이에 시작되었다.[4] 생애 업적 마크 주커버그는 1984년 5월 14일 미구 뉴욕주 노스암프턴에서 태어난 기업가이며, 페이스북의 창업자이자 CEO입니다.[1] 마크 주커버그는 세계에서 가장 큰 소셜 미디어 플랫폼 중 하나인 페이스북을 공동 설립한 것으로 가장 잘 알려진 미국의 기업가이자 소프트웨어 개발자이다.\n",
      "확률 분포에서 중앙값을 기준으로 양쪽의 넓이 또한 같아야 하지요.[4] 그런 극단값이 존재할 때는 평균보다는 중앙값을 사용한다.최빈값은 가장 많이 나타나는 값을, 중앙값은 데이터의 순서상 가운데에 있는 값을 의미합니다.데이터의 개수가 짝수인 경우는, 가운데에 오는 2 개의 값의 평균을 취합니다.그래서 극단값과 같은 이상치에 영향을 받지 않게 된다.\n",
      "[3] 르네상스 시대를 대표하는 예술가로 우리는 미켈란젤로를 뽑습니다.르네상스 대표 화가 <산드로 보티첼리> 산드로 보티첼리는 르네상스 시대를 대표하는 이탈리아 화가입니다.미켈란젤로는 이탈리아 르네상스 시대의 대표적인 예술가중 한 명으로, 조각과 회화 분야에서 활동하였습니다.[2] 2.[5] 이러한 발전은 유럽 문화의 발전과 함께 세계문화에 큰 영향을 미쳤습니다 .\n",
      "ISO 14001인증은 자연친화적 생산시스템 구축, 운영, 평가, 관리가 유지되고 있음을 내포하는 국제 인증이다.[3] 라닉스가 획득한 ISO 9001은 국제표준화기구(이하 ISO)에서 제정한 품질경영시스템에 대한 국제규격이다.품질 경영에 규정된 요구사항을 만족하고 지속적으로 관리하고 있음을 국제적으로 인증한다는 의미다.[1] 또 지난해 말에는 FCC 인증(전자파, 전파 규제기준 충족)을 갱신하고 ISO 45001(환경 경영) 인증 등을 취득했다.ISO 9001은 품질경영시스템 국제 규격으로 소비자에게 전달되는 서비스의 전 과정이 국내뿐만 아니라 국제 기준에도 부합함을 입증하는 기준이다.\n",
      "[2] 연방준비제도의 역할은 무엇인가?연방준비제도 즉 FED의 역할은 시장의 수요와 공급을 결정하는 역할을 합니다.[1] 연방준비제도, 종종 연준이라고도 불리는 연방준비제도는 미국의 중앙은행입니다.연준에는 통화 공급과 금리에 영향을 미치는 세 가지 주요 정책 도구가 있습니다.1913년 연방준비제도법에 의해 창설되었으며 통화정책 수행, 은행 감독 및 규제, 금융시스템의 안정성 유지 등을 담당하고 있습니다.\n",
      "여성 바둑 기사들의 부상과 그들이 바둑 게임에 미치는 영향을 살펴본다.[1] 중국 바둑의 역사 바둑은 2,500 년 전 춘추전국시대에 중국에 소개되었다 .19x19 그리드로 진행되며, 가능한 한 많은 영토를 포위하고 점령하는 것이 게임의 목적이다.바둑은 지식인들을 위한 게임으로 생각되었고 학자들과 귀족들에 의해 행해졌다 .오랜 역사를 가진 남성 위주의 게임이지만, 최근에는 이 게임에서 두각을 나타내고 있는 여성 바둑 기사들이 증가하고 있다.\n",
      "[3] 에펠탑은 파리에서 가장 유명한 지형학적 랜드마크 중 하나입니다.이 건축물은 1889년에 완성되었으며, 원래는 20년간 지속될 계획이었습니다.[1] 에펠탑 엘리베이터 기타 사항 1.1889년에 지어진 이 철탑은 높이가 324미터이고 전망대에서 도시의 멋진 전망을 제공합니다.방문객들은 계단이나 엘리베이터를 타고 꼭대기까지 올라가 타워의 식당 중 하나에서 식사를 즐길 수 있습니다.\n",
      "[3] 반도체는 ‘8대 공정’을 통해 제조된다.반도체 생산 과정은 크게 설계-웨이퍼 생산-패키징 및 테스트 등 3단계에 걸쳐 진행된다.[2] 높은 수율을 얻기 위해서는 공정 장비의 정확도와 클린룸의 청정도, 공정 조건 등 여러 제반 사항이 뒷받침돼야 한다.그중에서도 가장 기초가 되는 것이 웨이퍼(Wafer·원판) 제조 공정이다.2019년부터 미국의 반도체 제재가 본격화되면서 중국은 반도체 장비, 소재 확보에 어려움을 겪어왔습니다.\n",
      "세계에서 일류 와인 양조지가 가장 많은 와인 산지입니다.[1] < 지역별 와인의 특징 > 프랑스의 주요 와인 생산지역으로는 보르도, 부르고뉴, 로렌 밸리, 코르시카, 샴페인 등이 있습니다.보르도 지역의 와인은 타닌이 많고, 크게 붉은 와인과 흰 와인으로 나뉘어지며, 산미와 바디감이 강합니다.부르고뉴 지역은 피노 누아르와 샤르도네 와인이 유명하며, 가벼우면서도 풍미가 깊습니다.[2] 테이블 와인은 프랑스 와인 생산의 35% 정도를 차지하고 있으며 용기에 알코올 함량만 표기되고 이름이나 원산지 등이 표기되지 않아도 무방합니다.\n",
      "[4] 브라이언 메이(Brian May) : 퀸의 기타리스트로서, 그룹의 음악을 작곡하는 중요한 역할을 합니다.로저 테일러(Roger Taylor) : 퀸의 미모담당 , 노래를 부르기도 합니다.그중에는 'Bohemian Rhapsody', 'Somebody to Love', 'We Are the Champions', 'Don't Stop Me Now' 등이 있다.그는 1980년대 후반 인체 면역 결핍 바이러스 HIV에 감염되어 갑자기 건강이 악화되었다.[2] 프레디는 퀸 밴드의 대표 멤버로서 다양한 히트곡들을 만들어냈다.\n",
      "[2] 나폴레옹 보나파르트(Napoleon Bonaparte)는 누구인가?나폴레옹은 파리 육군사관학교에 재학 중에 육군 포병 소위로 임관하였다.나폴레옹 보나파르트는 프랑스의 황제로서 전쟁, 정치, 문화 등 다양한 분야에서 업적을 남겼습니다.[3] 흔히 나폴레옹(프랑스어: Napoléon, 문화어: 나뽈레옹)으로 불린다.코르시카 섬의 하급 귀족 가문 출신의 군인으로, 프랑스혁명 시기에 벌어진 전쟁에서 큰 공을 세우며 국민적 영웅이 되었고, 쿠데타를 통해 제1 통령이 된 후 종신통령을 거쳐서 황제에 즉위했다.\n",
      "강남성모병원 아시나요?자리도 쾌적하고 서초구에 위치하고 있어서 접근도 편한 편이다.[2] 1.국립중앙도서관 위치 및 교통 국립중앙도서관은 서울시 서초구에 위치합니다.게다가 자율배식이라 원하는 만큼 풀 수 있다.\n",
      "[2] S&P 500 지수는 국제 신용평가기관인 미국의 Standard and Poors (S&P)이 작성한 주가 지수이다.이 지수는 구성 기업의 가중치가 시가 총액을 좀더 정확하게 반영하도록 주기적으로 재조정됩니다.현재 S&P 500에 포함된 몇몇 회사들은 애플, 아마존, 페이스북, 구글 모회사 알파벳과 같은 그들의 산업에서 잘 알려진 거대 기업들이다.[4] 이 지수는 금융 서비스 회사인 Standard & Poor's 에 의해 만들어졌으며 투자자에게 미국 주식 시장의 성과에 대한 광범위한 측정을 제공하기 위한 수단으로 1957 년에 처음 도입되었습니다.[5] 이 지수는 금융 서비스 회사인 Standard & Poor's 에 의해 만들어졌으며 투자자에게 미국 주식 시장의 성과에 대한 광범위한 측정을 제공하기 위한 수단으로 1957 년에 처음 도입되었습니다.\n",
      "에어 조던은 농구 선수뿐만 아니라 일반인들도 스트릿 패션으로 즐겨 신는 인기 있는 슈즈 브랜드 중 하나입니다.1985년에 최초의 에어 조던 신발이 출시되었고 빠르게 문화 현상이 되었습니다.에어 조던 운동화는 마이클 조던을 위해 특별히 고안되었고, 그것들은 빠르게 농구 선수들과 팬들 사이에서 인기를 얻었습니다.에어 조던은 1984년에 최초로 출시되었으며, 이후 매년 새로운 디자인과 색상이 출시되고 있습니다.최초의 에어 조던 신발인 에어 조던 1은 1985년에 출시되었으며 농구 선수와 운동화 애호가들 사이에서 빠르게 인기를 얻었습니다.\n",
      "아인슈타인은 또한 양자 역학 연구와 현대 우주론의 발전에 중요한 기여를 했다.[2] 일반 상대성 일반 상대성 이론은 1915년 알버트 아인슈타인이 제안한 물리학의 기본 이론입니다.[1] 일반 상대성 일반 상대성 이론은 1915년 알버트 아인슈타인이 제안한 물리학의 기본 이론입니다.중력의 거동과 중력이 시공간 기하학에 미치는 영향을 설명합니다.이 원리는 갈릴레오 갈릴레이에 의해 이전에 제안되었고 아인슈타인 이전에 많은 과학자에 의해 실험적으로 확인되었습니다.\n",
      "Dataset({\n",
      "    features: ['text'],\n",
      "    num_rows: 150\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "dataset_dic = {\n",
    "    'text' :[]\n",
    "}\n",
    "for dataset in training_data:\n",
    "    format_data = f'<|begin_of_text|><|start_header_id|>context<|end_header_id|>\\n\\n{dataset[\"context\"]}<|eot_id|><|start_header_id|>question<|end_header_id|>\\n\\n{dataset[\"question\"]}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{dataset[\"chosen\"]}<|eot_id|><|end_of_text|>'\n",
    "    dataset_dic['text'].append(format_data)\n",
    "for i in range(2):\n",
    "    for dataset in training_data:\n",
    "        torch.cuda.empty_cache()\n",
    "        context = run_example(dataset['context'], dataset['question'])\n",
    "        format_data = f'<|begin_of_text|><|start_header_id|>context<|end_header_id|>\\n\\n{context}<|eot_id|><|start_header_id|>question<|end_header_id|>\\n\\n{dataset[\"question\"]}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{dataset[\"chosen\"]}<|eot_id|><|end_of_text|>'\n",
    "        dataset_dic['text'].append(format_data)\n",
    "dataset_training_data = Dataset.from_dict(dataset_dic)\n",
    "print(dataset_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA에서 사용하는 low-rank matrices 어텐션 차원을 정의. 여기서는 64로 설정\n",
    "# 값이 크면 클수록 더 많은 수정이 이루어지며, 모델이 더 복잡해질 수 있음\n",
    "lora_r = 64   \n",
    "\n",
    "# LoRA 적용 시 가중치에 곱해지는 스케일링 요소. 여기서는 16으로 설정\n",
    "# LoRA가 적용될 때 원래 모델의 가중치에 얼마나 영향을 미칠지 결정. 높은 값은 가중치 조정의 강도를 증가시킴\n",
    "lora_alpha = 16  \n",
    "\n",
    "# Dropout probability for LoRA layers   # LoRA 층에 적용되는 드롭아웃 확률. 여기서는 0.1 (10%)로 설정\n",
    "lora_dropout = 0.1 # 일부 네트워크 연결을 무작위로 비활성화하여 모델의 강건함에 기여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델이 예측한 결과와 체크포인트가 저장될 출력 디렉터리\n",
    "output_dir = \"./results\" \n",
    "\n",
    "# 훈련 에포크 수\n",
    "num_train_epochs = 2\n",
    "\n",
    "# fp16/bf16 학습 활성화(A100으로 bf16을 True로 설정)\n",
    "fp16 = False   \n",
    "bf16 = False   \n",
    "\n",
    "# 훈련용 배치 크기\n",
    "per_device_train_batch_size = 2\n",
    "\n",
    "# 평가용 배치 크기\n",
    "per_device_eval_batch_size = 1  \n",
    "\n",
    "# 그래디언트를 누적할 업데이트 스텝 횟수\n",
    "gradient_accumulation_steps = 1  \n",
    "\n",
    "# 그래디언트 체크포인트 활성화\n",
    "gradient_checkpointing = True  \n",
    "\n",
    "\n",
    "# 그래디언트 클리핑을 위한 최대 그래디언트 노름을 설정. \n",
    "# 그래디언트 클리핑은 그래디언트의 크기를 제한하여 훈련 중 안정성을 높임.\n",
    "# Maximum gradient normal (그래디언트 클리핑) 0.3으로 설정\n",
    "max_grad_norm = 0.3  \n",
    "\n",
    "# 초기 학습률 AdamW 옵티마이저\n",
    "learning_rate = 2e-6 \n",
    "\n",
    "# bias/LayerNorm 가중치를 제외하고 모든 레이어에 적용할 Weight decay 값\n",
    "weight_decay = 0.001 \n",
    "\n",
    "# 옵티마이저 설정\n",
    "optim = \"paged_adamw_32bit\"  \n",
    "\n",
    "# 학습률 스케줄러의 유형 설정, 여기서는 코사인 스케줄러 사용\n",
    "lr_scheduler_type = \"cosine\"   \n",
    "\n",
    "# 훈련 스텝 수(num_train_epochs 재정의)\n",
    "max_steps = -1 \n",
    "\n",
    "# (0부터 learning rate까지) 학습 초기에 학습률을 점진적으로 증가시키 linear warmup 스텝의 Ratio\n",
    "warmup_ratio = 0.03  \n",
    "\n",
    "# 시퀀스를 동일한 길이의 배치로 그룹화, 메모리 절약 및 훈련 속도를 높임\n",
    "group_by_length = True   \n",
    "\n",
    "# X 업데이트 단계마다 체크포인트 저장\n",
    "save_steps = 0  \n",
    "\n",
    "# 매 X 업데이트 스텝 로그\n",
    "logging_steps = 25  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 시퀀스 길이 설정\n",
    "max_seq_length = None \n",
    "\n",
    "# 동일한 입력 시퀀스에 여러 개의 짧은 예제를 넣어 효율성을 높일 수 있음\n",
    "packing = False  \n",
    "\n",
    "# GPU 0 전체 모델 로드 \n",
    "device_map = {\"\": 0}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-bit precision 기반의 모델 로드\n",
    "use_4bit = True \n",
    "\n",
    "# 4비트 기반 모델에 대한 dtype 계산\n",
    "bnb_4bit_compute_dtype = \"float16\" \n",
    "\n",
    "# 양자화 유형(fp4 또는 nf4)\n",
    "bnb_4bit_quant_type = \"nf4\" \n",
    "\n",
    "# 4비트 기 모델에 대해 중첩 양자화 활성화(이중 양자화)\n",
    "use_nested_quant = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_dtype = getattr(torch, bnb_4bit_compute_dtype)\n",
    "# 모델 계산에 사용될 데이터 타입 결정\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=use_4bit,  # 모델을 4비트로 로드할지 여부를 결정\n",
    "    bnb_4bit_quant_type=bnb_4bit_quant_type, # 양자화 유형을 설정\n",
    "    bnb_4bit_compute_dtype=compute_dtype,  # 계산에 사용될 데이터 타입을 설정\n",
    "    bnb_4bit_use_double_quant=use_nested_quant, # 중첩 양자화를 사용할지 여부를 결정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU don't supports bfloat16: accelerate training with bf16=False\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 만약 GPU가 최소한 버전 8 이상이라면 (major >= 8) bfloat16을 지원한다고 메시지를 출력. \n",
    "# bfloat16은 훈련 속도를 높일 수 있는 데이터 타입. \n",
    "\n",
    "if compute_dtype == torch.float16 and use_4bit:\n",
    "    major, _ = torch.cuda.get_device_capability()\n",
    "    if major >= 8:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU supports bfloat16: accelerate training with bf16=True\")\n",
    "        print(\"=\" * 80)\n",
    "    else:\n",
    "        print(\"=\" * 80)\n",
    "        print(\"Your GPU don\\'t supports bfloat16: accelerate training with bf16=False\")\n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training parameters\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    optim=optim,\n",
    "    save_steps=save_steps,\n",
    "    logging_steps=logging_steps,\n",
    "    learning_rate=learning_rate,\n",
    "    weight_decay=weight_decay,\n",
    "    fp16=fp16,\n",
    "    bf16=bf16,\n",
    "    max_grad_norm=max_grad_norm,\n",
    "    max_steps=max_steps,\n",
    "    warmup_ratio=warmup_ratio,\n",
    "    group_by_length=group_by_length,\n",
    "    lr_scheduler_type=lr_scheduler_type,\n",
    "    report_to=\"tensorboard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 52,428,800 || all params: 14,550,717,440 || trainable%: 0.3603\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model\n",
    "# Load LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=lora_alpha,\n",
    "    lora_dropout=lora_dropout,\n",
    "    r=lora_r,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\", # 파인튜닝할 태스크를 Optional로 지정할 수 있는데, 여기서는 CASUAL_LM을 지정하였다.\n",
    ")\n",
    "model = get_peft_model(base_model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dxlab/anaconda3/envs/obqa/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': dataset_text_field. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/dxlab/anaconda3/envs/obqa/lib/python3.11/site-packages/transformers/training_args.py:1815: FutureWarning: `--push_to_hub_token` is deprecated and will be removed in version 5 of 🤗 Transformers. Use `--hub_token` instead.\n",
      "  warnings.warn(\n",
      "/home/dxlab/anaconda3/envs/obqa/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:278: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n",
      "/home/dxlab/anaconda3/envs/obqa/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:307: UserWarning: You passed a `dataset_text_field` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4fa5389fec44a5bfaa1e43eca25c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dxlab/anaconda3/envs/obqa/lib/python3.11/site-packages/accelerate/accelerator.py:444: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Trainer with LoRA configuration\n",
    "# Set supervised fine-tuning parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=base_model,\n",
    "    train_dataset=dataset_training_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    tokenizer=base_tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing=packing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 18:33, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.036200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.415300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>2.419200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>2.166900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>2.376900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>2.317800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dxlab/anaconda3/envs/obqa/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "trainer.train()\n",
    "# Save trained model\n",
    "trainer.model.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1efccff5244065b309d412fc3a3dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# base_model과 new_model에 저장된 LoRA 가중치를 통합하여 새로운 모델을 생성\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_dir,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "model = PeftModel.from_pretrained(base_model, new_model) # LoRA 가중치를 가져와 기본 모델에 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context sentences: ['[1] 이어 최근 주식 보유 비중을 높인 일본 종합상사에 대해서는 “앞으로 100년 동안, 아니 영원히 살아남을 기업”이라고 말했다.', '저평가된 우량주를 매입해 장기 보유하는 가치 투자 방식을 고집하는 버핏은 2020년 8월 이후부터 이토추상사, 마루베니, 미쓰비시상사, 미쓰이물산, 스미토모상사 등 일본 5대 종합상사의 주식을 사들여왔다.', '버핏의 일본 종합상사 주식 보유 비중은 점차 늘어 최근에는 7.4%까지 늘어난 것으로 알려졌다.', '[2] 적극적으로 행사해 그 차이를 빠르게 줄이는 전략이다.', '그레이엄의 수제자인 워런 버핏도 이 같은 행동주의 전략을 적극 활용했다.', '이후 행동주의는 1980~1990년대 ‘기업 사냥꾼 시대’를 거쳐 2000년대 들어 헤지펀드의 다양한 투자 전략 중 하나로 자리잡았다.', '[3] 그는 내년에 은행 파산으로 예금 손실을 보는 미국인은 없을 것이란 데 100만달러를 건다면서 반대의 경우에 돈을 거는 사람이 있다면 지는 사람이 200만달러를 자선단체에 기부하자는 제안도 했습니다.', '한편 버핏은 최근 지분을 축소한 중국 전기차 업체 비야디(BYD)와 대만 반도체 업체 TSMC에 대해서는 여전히 기업가치를 높게 평가하고 있다고 밝혔습니다.']\n",
      "Context input IDs shape: torch.Size([8, 66])\n",
      "Question input IDs shape: torch.Size([1, 15])\n",
      "Number of context sentences: 8\n",
      "Scores shape: torch.Size([8, 16])\n",
      "Scores: tensor([[1665.2512, 1665.2512, 1665.2512, 1665.2512, 1665.2512, 1665.2512,\n",
      "         1665.2512, 1665.2512, 1665.2512, 1665.2512, 1665.2512, 1665.2512,\n",
      "         1665.2512, 1665.2512, 1665.2512, 1665.2512],\n",
      "        [2108.7971, 2108.7971, 2108.7971, 2108.7971, 2108.7971, 2108.7971,\n",
      "         2108.7971, 2108.7971, 2108.7971, 2108.7971, 2108.7971, 2108.7971,\n",
      "         2108.7971, 2108.7971, 2108.7971, 2108.7971],\n",
      "        [2981.9678, 2981.9678, 2981.9678, 2981.9678, 2981.9678, 2981.9678,\n",
      "         2981.9678, 2981.9678, 2981.9678, 2981.9678, 2981.9678, 2981.9678,\n",
      "         2981.9678, 2981.9678, 2981.9678, 2981.9678],\n",
      "        [5409.0225, 5409.0225, 5409.0225, 5409.0225, 5409.0225, 5409.0225,\n",
      "         5409.0225, 5409.0225, 5409.0225, 5409.0225, 5409.0225, 5409.0225,\n",
      "         5409.0225, 5409.0225, 5409.0225, 5409.0225],\n",
      "        [4347.7148, 4347.7148, 4347.7148, 4347.7148, 4347.7148, 4347.7148,\n",
      "         4347.7148, 4347.7148, 4347.7148, 4347.7148, 4347.7148, 4347.7148,\n",
      "         4347.7148, 4347.7148, 4347.7148, 4347.7148],\n",
      "        [5012.0742, 5012.0742, 5012.0742, 5012.0742, 5012.0742, 5012.0742,\n",
      "         5012.0742, 5012.0742, 5012.0742, 5012.0742, 5012.0742, 5012.0742,\n",
      "         5012.0742, 5012.0742, 5012.0742, 5012.0742],\n",
      "        [2457.4907, 2457.4907, 2457.4907, 2457.4907, 2457.4907, 2457.4907,\n",
      "         2457.4907, 2457.4907, 2457.4907, 2457.4907, 2457.4907, 2457.4907,\n",
      "         2457.4907, 2457.4907, 2457.4907, 2457.4907],\n",
      "        [2863.8743, 2863.8743, 2863.8743, 2863.8743, 2863.8743, 2863.8743,\n",
      "         2863.8743, 2863.8743, 2863.8743, 2863.8743, 2863.8743, 2863.8743,\n",
      "         2863.8743, 2863.8743, 2863.8743, 2863.8743]])\n",
      "[1665.251220703125, 2108.797119140625, 2981.9677734375, 5409.0224609375, 4347.71484375, 5012.07421875, 2457.49072265625, 2863.874267578125]\n",
      "[(3, 5409.0224609375), (5, 5012.07421875), (4, 4347.71484375), (2, 2981.9677734375), (7, 2863.874267578125), (6, 2457.49072265625), (1, 2108.797119140625), (0, 1665.251220703125)]\n",
      "Top 5 sentence indices: [3, 5, 4, 2, 7]\n",
      "[2] 적극적으로 행사해 그 차이를 빠르게 줄이는 전략이다.이후 행동주의는 1980~1990년대 ‘기업 사냥꾼 시대’를 거쳐 2000년대 들어 헤지펀드의 다양한 투자 전략 중 하나로 자리잡았다.그레이엄의 수제자인 워런 버핏도 이 같은 행동주의 전략을 적극 활용했다.버핏의 일본 종합상사 주식 보유 비중은 점차 늘어 최근에는 7.4%까지 늘어난 것으로 알려졌다.한편 버핏은 최근 지분을 축소한 중국 전기차 업체 비야디(BYD)와 대만 반도체 업체 TSMC에 대해서는 여전히 기업가치를 높게 평가하고 있다고 밝혔습니다.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f558865b02bc43369d415df44c6101e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'context',\n",
       "    'content': '[2] 적극적으로 행사해 그 차이를 빠르게 줄이는 전략이다.이후 행동주의는 1980~1990년대 ‘기업 사냥꾼 시대’를 거쳐 2000년대 들어 헤지펀드의 다양한 투자 전략 중 하나로 자리잡았다.그레이엄의 수제자인 워런 버핏도 이 같은 행동주의 전략을 적극 활용했다.버핏의 일본 종합상사 주식 보유 비중은 점차 늘어 최근에는 7.4%까지 늘어난 것으로 알려졌다.한편 버핏은 최근 지분을 축소한 중국 전기차 업체 비야디(BYD)와 대만 반도체 업체 TSMC에 대해서는 여전히 기업가치를 높게 평가하고 있다고 밝혔습니다.'},\n",
       "   {'role': 'question', 'content': '워런 버핏이 제안하는 투자 전략은 무엇인가요?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': '“나는 투자는 기업의 일부를 사는 것이라고 생각한다.그리고 나는 기업의 일부를 살 때 그 회사를 잘 이해하려고 노력한다.”(워런 버핏 버크셔해서웨이 회장)버핏 회장은 ‘투자 대가’ 답게 주식 투자의 본질에 대해 명확하게 정의하고 있습니다.즉 기업을 살 때 해당 기업을 제대로 파악하고 주식을 매입해야 한다는 겁니다.주식 투자를 하는 사람은 누구나 ‘장기투자’를 하고 싶어합니다.하지만 기업의 가치에 대해 제대로 파악하지 못한 채 투자를 하는 것은 장기투자라고 말할 수 없습니다.버핏 회장은 “장기 투자는 단순히 오래 보유하기 위해서 하는 것이 아니라 기업의 가치를 제대로 파악한 후 기업의 일부를 사서 오랫동안 보유하는 것”이라며 “투자 기간이 길수록 기업의 가치가 높아지고, 장기 투자에 성공할 확률이 높아진다”고 주장합니다.버핏 회장은 기업의'}]}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Generate text using fine-tuned model\n",
    "context = '\t열사병을 예방하는 방법 겨울보다 여름철 유독 많이 발생하는 열사병을 예방하기 위해서는 고온 다습하고 더운 환경에 노출하지 않는 게 좋습니다. 강한 자외선과 더운 날씨에 외출을 가급적 삼가를 해야 하며 몸으로 빠져나가는 수분을 이온음료, 물 등을 수시로 섭취하여 보충해줘야 합니다. 심할 경우 사망에까지 이를 수 있으므로 각별히 주의해야 하는데요, 응급처치로는 환자를 그늘지고 시원한 곳으로 옮긴 후 옷을 느슨하게 풀어주고 물수건으로 닦아주는 방법이 있습니다. 특히 온열질환의 초기 증상은 대체적으로 약한 두통과 어지러움 그리고 속이 울렁거린다는 공통점이 있는데요 이러한 증상을 시작으로 점점 심화되기 때문에 초기에 나타나는 증상을 가급적 빨리 감지하고 조치를 하면 좋습니다. 그런데 요즘은 더위가 빨리 찾아오고, 불가피하게 폭염특보 때문에 외출을 하는 사람들이 많아 이런 병에 걸리는 경우가 많았습니다. 따라서 부득이하게 야외에 나갈 때는 챙이 넓은 모자를 쓰고 헐렁한 옷을 입는 것이 좋습니다. 또한, 규칙적으로 물을 마시고 몸에 수분이 부족하지 않도록 주의하는 것도 좋습니다. 무엇보다 일사병 증상 중 정신이상이 나타나는 경우 열사병으로 의심해 보아야 하기 때문에 반드시 병원 진료를 받아야합니다. 일사병은 대체적으로 염분과 수분의 부족으로 나타나는 경우가 많으므로 규칙적인 수분 섭취를 통해 예방할 수 있습니다. 일시적으로 일사병의 증상이 나타나는 경우 서늘한 곳에서 휴식을 취하고 수분을 섭취하면 호전되는 경우가 많습니다. 무엇보다 일사병 증상 중 정신이상이 나타나는 경우 열사병으로 의심해 보아야 하기 때문에 반드시 병원 진료를 받아야합니다. 일사병은 대체적으로 염분과 수분의 부족으로 나타나는 경우가 많으므로 규칙적인 수분 섭취를 통해 예방할 수 있습니다. 일시적으로 일사병의 증상이 나타나는 경우 서늘한 곳에서 휴식을 취하고 수분을 섭취하면 호전되는 경우가 많습니다.'\n",
    "question = '여름철에 많이 생기는 열사병을 예방하는 방법은 무엇인가요?'\n",
    "query =  f'<|begin_of_text|><|start_header_id|>context<|end_header_id|>\\n\\n{context}<|eot_id|><|start_header_id|>question<|end_header_id|>\\n\\n{question}<|eot_id|><|start_header_id|>answer<|end_header_id|>\\n\\n'\n",
    "query_4 = f'<|begin_of_text|><|start_header_id|>context<|end_header_id|>\\n\\n{context}<|eot_id|><|start_header_id|>question<|end_header_id|>\\n\\n{question}<|eot_id|>'\n",
    "\n",
    "ex_question =  \"워런 버핏이 제안하는 투자 전략은 무엇인가요?\"\n",
    "ex_context = \"[1] 이어 최근 주식 보유 비중을 높인 일본 종합상사에 대해서는 “앞으로 100년 동안, 아니 영원히 살아남을 기업”이라고 말했다. 저평가된 우량주를 매입해 장기 보유하는 가치 투자 방식을 고집하는 버핏은 2020년 8월 이후부터 이토추상사, 마루베니, 미쓰비시상사, 미쓰이물산, 스미토모상사 등 일본 5대 종합상사의 주식을 사들여왔다. 버핏의 일본 종합상사 주식 보유 비중은 점차 늘어 최근에는 7.4%까지 늘어난 것으로 알려졌다. [2] 적극적으로 행사해 그 차이를 빠르게 줄이는 전략이다. 그레이엄의 수제자인 워런 버핏도 이 같은 행동주의 전략을 적극 활용했다. 이후 행동주의는 1980~1990년대 ‘기업 사냥꾼 시대’를 거쳐 2000년대 들어 헤지펀드의 다양한 투자 전략 중 하나로 자리잡았다. [3] 그는 내년에 은행 파산으로 예금 손실을 보는 미국인은 없을 것이란 데 100만달러를 건다면서 반대의 경우에 돈을 거는 사람이 있다면 지는 사람이 200만달러를 자선단체에 기부하자는 제안도 했습니다. 한편 버핏은 최근 지분을 축소한 중국 전기차 업체 비야디(BYD)와 대만 반도체 업체 TSMC에 대해서는 여전히 기업가치를 높게 평가하고 있다고 밝혔습니다.\" \n",
    "ex_answer =  \"워렌 버핏은 주식 투자에서 가치 투자 전략을 제안합니다. 이는 저평가된 우량주를 장기간 보유하는 방식으로, 일본 종합상사들의 주식을 매입해 이를 실천하고 있습니다. 이 전략은 장기적인 시각으로 기업의 가치를 평가하고, 저렴하게 평가된 주식을 구매하여 해당 기업이 성장하고 가치를 높일 때까지 보유하는 것을 목표로 합니다.\"\n",
    "\n",
    "\n",
    "context_2 = \"\"\"\n",
    "열사병을 예방하는 방법 겨울보다 여름철 유독 많이 발생하는 열사병을 예방하기 위해서는 고온 다습하고 더운 환경에 노출하지 않는 게 좋습니다. 강한 자외선과 더운 날씨에 외출을 가급적 삼가를 해야 하며 몸으로 빠져나가는 수분을 이온음료, 물 등을 수시로 섭취하여 보충해줘야 합니다.\n",
    "심할 경우 사망에까지 이를 수 있으므로 각별히 주의해야 하는데요, 응급처치로는 환자를 그늘지고 시원한 곳으로 옮긴 후 옷을 느슨하게 풀어주고 물수건으로 닦아주는 방법이 있습니다. 특히 온열질환의 초기 증상은 대체적으로 약한 두통과 어지러움 그리고 속이 울렁거린다는 공통점이 있는데요 이러한 증상을 시작으로 점점 심화되기 때문에 초기에 나타나는 증상을 가급적 빨리 감지하고 조치를 하면 좋습니다.\n",
    "그런데 요즘은 더위가 빨리 찾아오고, 불가피하게 폭염특보 때문에 외출을 하는 사람들이 많아 이런 병에 걸리는 경우가 많았습니다. 따라서 부득이하게 야외에 나갈 때는 챙이 넓은 모자를 쓰고 헐렁한 옷을 입는 것이 좋습니다. 또한, 규칙적으로 물을 마시고 몸에 수분이 부족하지 않도록 주의하는 것도 좋습니다.\n",
    "무엇보다 일사병 증상 중 정신이상이 나타나는 경우 열사병으로 의심해 보아야 하기 때문에 반드시 병원 진료를 받아야합니다. 일사병은 대체적으로 염분과 수분의 부족으로 나타나는 경우가 많으므로 규칙적인 수분 섭취를 통해 예방할 수 있습니다. 일시적으로 일사병의 증상이 나타나는 경우 서늘한 곳에서 휴식을 취하고 수분을 섭취하면 호전되는 경우가 많습니다.\n",
    "\"\"\"\n",
    "query_2 = f'context: {context_2} question:{question} context의 내용을 근거로 question의 내용에 답변알려줘'\n",
    "query_3 = f'{context_2}{question}'\n",
    "\n",
    "message = [\n",
    "    {\"role\": \"system\", \"content\": query_3}\n",
    "]\n",
    "\n",
    "poly_context = run_example(ex_context, ex_question)\n",
    "\n",
    "message_2 = [\n",
    "    {\"role\": \"context\", \"content\": poly_context},\n",
    "    {\"role\": \"question\", \"content\": ex_question}\n",
    "]\n",
    "\n",
    "text_gen = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=new_model, \n",
    "    tokenizer=base_tokenizer,\n",
    "    max_new_tokens=200,\n",
    "    do_sample=True,\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "text_gen(message_2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
